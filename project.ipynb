{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.callbacks import CSVLogger\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = open('keptcolumns.txt', 'r')\n",
    "keptcolumns = fi.read().rstrip('\\n').split(', ')\n",
    "keptcolumns = np.array(keptcolumns)\n",
    "data = pd.read_csv('epi_r.csv', usecols = keptcolumns)\n",
    "data = data[pd.notnull(data['calories'])]\n",
    "data = data[pd.notnull(data['protein'])]\n",
    "data = data[pd.notnull(data['fat'])]\n",
    "data = data[data['calories'] != 0]\n",
    "data = data[data['protein'] != 0]\n",
    "data = data[data['fat'] != 0]\n",
    "data = data.values\n",
    "h_val = data[:, 0:6]\n",
    "ingred = data[:, 6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dat(xy):\n",
    "    cnt = np.sum(xy == 1)\n",
    "    idx = np.where(xy == 1)\n",
    "    x = np.zeros((cnt, xy.shape[0]))\n",
    "    y = np.zeros((cnt, xy.shape[0]))\n",
    "    for i in range(cnt):\n",
    "        y_idx = idx[0][i];\n",
    "        x_idx = np.setdiff1d(idx[0], y_idx)\n",
    "        y[i, y_idx] = 1\n",
    "        x[i, x_idx] = 1\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58058, 308)\n",
      "(58058, 308)\n"
     ]
    }
   ],
   "source": [
    "x = np.empty((0, ingred.shape[1]))\n",
    "y = np.empty((0, ingred.shape[1]))\n",
    "for i in range(ingred.shape[0]):\n",
    "    x_tmp, y_tmp = gen_dat(ingred[i])\n",
    "    x = np.append(x, x_tmp, axis = 0)\n",
    "    y = np.append(y, y_tmp, axis = 0)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46446, 308)\n",
      "(46446, 308)\n",
      "(11612, 308)\n",
      "(11612, 308)\n"
     ]
    }
   ],
   "source": [
    "idx = np.arange(x.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "x = x[idx]\n",
    "y = y[idx]\n",
    "p = x.shape[0] * 8 // 10\n",
    "x_train = x[:p, :]\n",
    "y_train = y[:p, :]\n",
    "x_test = x[p:, :]\n",
    "y_test = y[p:, :]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 200)               61800     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 300)               60300     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 308)               92708     \n",
      "=================================================================\n",
      "Total params: 485,708\n",
      "Trainable params: 485,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential([Dense(200, input_shape=(308,)),\n",
    "                                    LeakyReLU(),\n",
    "                                    \n",
    "                                    Dense(300),\n",
    "                                    LeakyReLU(),\n",
    "                                    \n",
    "                                    Dense(300),\n",
    "                                    LeakyReLU(),\n",
    "                                                                                                            \n",
    "                                    Dense(300),\n",
    "                                    LeakyReLU(),\n",
    "                                    \n",
    "                                    Dense(300),\n",
    "                                    LeakyReLU(),\n",
    "                                    \n",
    "                                    Dense(308, activation='sigmoid')\n",
    "                                   ])\n",
    "model1.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "46446/46446 [==============================] - 6s 120us/step - loss: 4.8122 - categorical_accuracy: 0.0281\n",
      "Epoch 2/22\n",
      "46446/46446 [==============================] - 6s 120us/step - loss: 4.3589 - categorical_accuracy: 0.0497\n",
      "Epoch 3/22\n",
      "46446/46446 [==============================] - 5s 117us/step - loss: 4.1604 - categorical_accuracy: 0.0711\n",
      "Epoch 4/22\n",
      "46446/46446 [==============================] - 6s 126us/step - loss: 3.9999 - categorical_accuracy: 0.1031\n",
      "Epoch 5/22\n",
      "46446/46446 [==============================] - 5s 106us/step - loss: 3.8448 - categorical_accuracy: 0.1341\n",
      "Epoch 6/22\n",
      "46446/46446 [==============================] - 4s 92us/step - loss: 3.6976 - categorical_accuracy: 0.1557\n",
      "Epoch 7/22\n",
      "46446/46446 [==============================] - 4s 87us/step - loss: 3.5530 - categorical_accuracy: 0.1765\n",
      "Epoch 8/22\n",
      "46446/46446 [==============================] - 4s 86us/step - loss: 3.4164 - categorical_accuracy: 0.1939\n",
      "Epoch 9/22\n",
      "46446/46446 [==============================] - 5s 99us/step - loss: 3.2893 - categorical_accuracy: 0.2095\n",
      "Epoch 10/22\n",
      "46446/46446 [==============================] - 4s 86us/step - loss: 3.1622 - categorical_accuracy: 0.2273\n",
      "Epoch 11/22\n",
      "46446/46446 [==============================] - 4s 85us/step - loss: 3.0395 - categorical_accuracy: 0.2451\n",
      "Epoch 12/22\n",
      "46446/46446 [==============================] - 4s 85us/step - loss: 2.9139 - categorical_accuracy: 0.2672\n",
      "Epoch 13/22\n",
      "46446/46446 [==============================] - 4s 85us/step - loss: 2.7946 - categorical_accuracy: 0.2885\n",
      "Epoch 14/22\n",
      "46446/46446 [==============================] - 5s 100us/step - loss: 2.6694 - categorical_accuracy: 0.3085\n",
      "Epoch 15/22\n",
      "46446/46446 [==============================] - 4s 86us/step - loss: 2.5553 - categorical_accuracy: 0.3320\n",
      "Epoch 16/22\n",
      "46446/46446 [==============================] - 4s 86us/step - loss: 2.4461 - categorical_accuracy: 0.3502\n",
      "Epoch 17/22\n",
      "46446/46446 [==============================] - 5s 113us/step - loss: 2.3353 - categorical_accuracy: 0.3745\n",
      "Epoch 18/22\n",
      "46446/46446 [==============================] - 6s 137us/step - loss: 2.2285 - categorical_accuracy: 0.3961\n",
      "Epoch 19/22\n",
      "46446/46446 [==============================] - 6s 135us/step - loss: 2.1343 - categorical_accuracy: 0.4159\n",
      "Epoch 20/22\n",
      "46446/46446 [==============================] - 5s 116us/step - loss: 2.0476 - categorical_accuracy: 0.4338\n",
      "Epoch 21/22\n",
      "46446/46446 [==============================] - 5s 102us/step - loss: 1.9541 - categorical_accuracy: 0.4534\n",
      "Epoch 22/22\n",
      "46446/46446 [==============================] - 5s 103us/step - loss: 1.8666 - categorical_accuracy: 0.4726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe1ade19a20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_logger = CSVLogger('training1.log')\n",
    "model1.fit(x_train, y_train, epochs = 22, batch_size = 128, callbacks = [csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "x = ingred\n",
    "calories = h_val[:, 2]\n",
    "protein = h_val[:, 3]\n",
    "fat = h_val[:, 4]\n",
    "y = protein / (calories * fat)\n",
    "print(np.where(y == 0))\n",
    "idx = np.argsort(y)\n",
    "idx = idx[:-250]\n",
    "np.random.shuffle(idx)\n",
    "x = x[idx]\n",
    "y = y[idx]\n",
    "maxi = np.max(y)\n",
    "y = y / maxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 200)               61800     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 500)               100500    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 1,164,801\n",
      "Trainable params: 1,164,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential([Dense(200, input_shape=(308,)),\n",
    "                                    LeakyReLU(),\n",
    "                                    \n",
    "                                    Dense(500),\n",
    "                                    LeakyReLU(),\n",
    "                                    \n",
    "                                    Dense(500),\n",
    "                                    LeakyReLU(),\n",
    "                    \n",
    "                                    Dense(500),\n",
    "                                    LeakyReLU(),\n",
    "                    \n",
    "                                    Dense(500),\n",
    "                                    LeakyReLU(),\n",
    "                    \n",
    "                                    Dense(500),\n",
    "                                    LeakyReLU(),\n",
    "                                                        \n",
    "                                    Dense(1)\n",
    "                                   ])\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14123/14123 [==============================] - 2s 135us/step - loss: 0.0267\n",
      "Epoch 2/100\n",
      "14123/14123 [==============================] - 2s 109us/step - loss: 0.0170\n",
      "Epoch 3/100\n",
      "14123/14123 [==============================] - 2s 110us/step - loss: 0.0154\n",
      "Epoch 4/100\n",
      "14123/14123 [==============================] - 2s 110us/step - loss: 0.0143\n",
      "Epoch 5/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0131\n",
      "Epoch 6/100\n",
      "14123/14123 [==============================] - 2s 114us/step - loss: 0.0120\n",
      "Epoch 7/100\n",
      "14123/14123 [==============================] - 2s 112us/step - loss: 0.0111\n",
      "Epoch 8/100\n",
      "14123/14123 [==============================] - 2s 116us/step - loss: 0.0097\n",
      "Epoch 9/100\n",
      "14123/14123 [==============================] - 2s 117us/step - loss: 0.0088\n",
      "Epoch 10/100\n",
      "14123/14123 [==============================] - 2s 128us/step - loss: 0.0082\n",
      "Epoch 11/100\n",
      "14123/14123 [==============================] - 2s 117us/step - loss: 0.0076\n",
      "Epoch 12/100\n",
      "14123/14123 [==============================] - 2s 125us/step - loss: 0.0069\n",
      "Epoch 13/100\n",
      "14123/14123 [==============================] - 2s 122us/step - loss: 0.0067\n",
      "Epoch 14/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0063\n",
      "Epoch 15/100\n",
      "14123/14123 [==============================] - 2s 118us/step - loss: 0.0059\n",
      "Epoch 16/100\n",
      "14123/14123 [==============================] - 2s 132us/step - loss: 0.0059\n",
      "Epoch 17/100\n",
      "14123/14123 [==============================] - 2s 152us/step - loss: 0.0056\n",
      "Epoch 18/100\n",
      "14123/14123 [==============================] - 2s 158us/step - loss: 0.0052\n",
      "Epoch 19/100\n",
      "14123/14123 [==============================] - 2s 167us/step - loss: 0.0049\n",
      "Epoch 20/100\n",
      "14123/14123 [==============================] - 2s 150us/step - loss: 0.0047\n",
      "Epoch 21/100\n",
      "14123/14123 [==============================] - 2s 130us/step - loss: 0.0046\n",
      "Epoch 22/100\n",
      "14123/14123 [==============================] - 2s 127us/step - loss: 0.0046\n",
      "Epoch 23/100\n",
      "14123/14123 [==============================] - 2s 130us/step - loss: 0.0044\n",
      "Epoch 24/100\n",
      "14123/14123 [==============================] - 2s 122us/step - loss: 0.0040\n",
      "Epoch 25/100\n",
      "14123/14123 [==============================] - 2s 122us/step - loss: 0.0041\n",
      "Epoch 26/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0040\n",
      "Epoch 27/100\n",
      "14123/14123 [==============================] - 2s 122us/step - loss: 0.0039\n",
      "Epoch 28/100\n",
      "14123/14123 [==============================] - 2s 149us/step - loss: 0.0040\n",
      "Epoch 29/100\n",
      "14123/14123 [==============================] - 2s 126us/step - loss: 0.0039\n",
      "Epoch 30/100\n",
      "14123/14123 [==============================] - 2s 122us/step - loss: 0.0038\n",
      "Epoch 31/100\n",
      "14123/14123 [==============================] - 2s 156us/step - loss: 0.0037\n",
      "Epoch 32/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0039\n",
      "Epoch 33/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0038\n",
      "Epoch 34/100\n",
      "14123/14123 [==============================] - 2s 120us/step - loss: 0.0039\n",
      "Epoch 35/100\n",
      "14123/14123 [==============================] - 2s 124us/step - loss: 0.0037\n",
      "Epoch 36/100\n",
      "14123/14123 [==============================] - 2s 130us/step - loss: 0.0036\n",
      "Epoch 37/100\n",
      "14123/14123 [==============================] - 2s 124us/step - loss: 0.0037\n",
      "Epoch 38/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0034\n",
      "Epoch 39/100\n",
      "14123/14123 [==============================] - 2s 124us/step - loss: 0.0034\n",
      "Epoch 40/100\n",
      "14123/14123 [==============================] - 2s 129us/step - loss: 0.0034\n",
      "Epoch 41/100\n",
      "14123/14123 [==============================] - 2s 122us/step - loss: 0.0034\n",
      "Epoch 42/100\n",
      "14123/14123 [==============================] - 2s 124us/step - loss: 0.0033\n",
      "Epoch 43/100\n",
      "14123/14123 [==============================] - 2s 170us/step - loss: 0.0034\n",
      "Epoch 44/100\n",
      "14123/14123 [==============================] - 2s 131us/step - loss: 0.0034\n",
      "Epoch 45/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0034\n",
      "Epoch 46/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0033\n",
      "Epoch 47/100\n",
      "14123/14123 [==============================] - 2s 120us/step - loss: 0.0035\n",
      "Epoch 48/100\n",
      "14123/14123 [==============================] - 2s 122us/step - loss: 0.0037\n",
      "Epoch 49/100\n",
      "14123/14123 [==============================] - 2s 125us/step - loss: 0.0036\n",
      "Epoch 50/100\n",
      "14123/14123 [==============================] - 2s 122us/step - loss: 0.0035\n",
      "Epoch 51/100\n",
      "14123/14123 [==============================] - 2s 123us/step - loss: 0.0034\n",
      "Epoch 52/100\n",
      "14123/14123 [==============================] - 2s 123us/step - loss: 0.0033\n",
      "Epoch 53/100\n",
      "14123/14123 [==============================] - 2s 124us/step - loss: 0.0033\n",
      "Epoch 54/100\n",
      "14123/14123 [==============================] - 2s 134us/step - loss: 0.0033\n",
      "Epoch 55/100\n",
      "14123/14123 [==============================] - 3s 196us/step - loss: 0.0033\n",
      "Epoch 56/100\n",
      "14123/14123 [==============================] - 2s 124us/step - loss: 0.0033\n",
      "Epoch 57/100\n",
      "14123/14123 [==============================] - 2s 125us/step - loss: 0.0032\n",
      "Epoch 58/100\n",
      "14123/14123 [==============================] - 2s 124us/step - loss: 0.0031\n",
      "Epoch 59/100\n",
      "14123/14123 [==============================] - 2s 127us/step - loss: 0.0031\n",
      "Epoch 60/100\n",
      "14123/14123 [==============================] - 2s 126us/step - loss: 0.0030\n",
      "Epoch 61/100\n",
      "14123/14123 [==============================] - 2s 123us/step - loss: 0.0030\n",
      "Epoch 62/100\n",
      "14123/14123 [==============================] - 2s 123us/step - loss: 0.0030\n",
      "Epoch 63/100\n",
      "14123/14123 [==============================] - 2s 124us/step - loss: 0.0030\n",
      "Epoch 64/100\n",
      "14123/14123 [==============================] - 2s 124us/step - loss: 0.0031\n",
      "Epoch 65/100\n",
      "14123/14123 [==============================] - 2s 123us/step - loss: 0.0030\n",
      "Epoch 66/100\n",
      "14123/14123 [==============================] - 2s 128us/step - loss: 0.0031\n",
      "Epoch 67/100\n",
      "14123/14123 [==============================] - 3s 187us/step - loss: 0.0031\n",
      "Epoch 68/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0030\n",
      "Epoch 69/100\n",
      "14123/14123 [==============================] - 2s 120us/step - loss: 0.0031\n",
      "Epoch 70/100\n",
      "14123/14123 [==============================] - 2s 122us/step - loss: 0.0030\n",
      "Epoch 71/100\n",
      "14123/14123 [==============================] - 2s 120us/step - loss: 0.0031\n",
      "Epoch 72/100\n",
      "14123/14123 [==============================] - 2s 123us/step - loss: 0.0031\n",
      "Epoch 73/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0031\n",
      "Epoch 74/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0031\n",
      "Epoch 75/100\n",
      "14123/14123 [==============================] - 2s 123us/step - loss: 0.0031\n",
      "Epoch 76/100\n",
      "14123/14123 [==============================] - 2s 122us/step - loss: 0.0031\n",
      "Epoch 77/100\n",
      "14123/14123 [==============================] - 2s 122us/step - loss: 0.0031\n",
      "Epoch 78/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0030\n",
      "Epoch 79/100\n",
      "14123/14123 [==============================] - 3s 190us/step - loss: 0.0029\n",
      "Epoch 80/100\n",
      "14123/14123 [==============================] - 2s 120us/step - loss: 0.0030\n",
      "Epoch 81/100\n",
      "14123/14123 [==============================] - 2s 120us/step - loss: 0.0030\n",
      "Epoch 82/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0030\n",
      "Epoch 83/100\n",
      "14123/14123 [==============================] - 2s 122us/step - loss: 0.0029\n",
      "Epoch 84/100\n",
      "14123/14123 [==============================] - 2s 122us/step - loss: 0.0029\n",
      "Epoch 85/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0030\n",
      "Epoch 86/100\n",
      "14123/14123 [==============================] - 2s 123us/step - loss: 0.0030\n",
      "Epoch 87/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0030\n",
      "Epoch 88/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0030\n",
      "Epoch 89/100\n",
      "14123/14123 [==============================] - 2s 122us/step - loss: 0.0029\n",
      "Epoch 90/100\n",
      "14123/14123 [==============================] - 2s 121us/step - loss: 0.0030\n",
      "Epoch 91/100\n",
      "14123/14123 [==============================] - 2s 137us/step - loss: 0.0030\n",
      "Epoch 92/100\n",
      "14123/14123 [==============================] - 2s 122us/step - loss: 0.0030\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14123/14123 [==============================] - 2s 120us/step - loss: 0.0030\n",
      "Epoch 94/100\n",
      "14123/14123 [==============================] - 2s 119us/step - loss: 0.0029\n",
      "Epoch 95/100\n",
      "14123/14123 [==============================] - 2s 119us/step - loss: 0.0029\n",
      "Epoch 96/100\n",
      "14123/14123 [==============================] - 2s 119us/step - loss: 0.0029\n",
      "Epoch 97/100\n",
      "14123/14123 [==============================] - 2s 120us/step - loss: 0.0030\n",
      "Epoch 98/100\n",
      "14123/14123 [==============================] - 2s 120us/step - loss: 0.0030\n",
      "Epoch 99/100\n",
      "14123/14123 [==============================] - 2s 119us/step - loss: 0.0030\n",
      "Epoch 100/100\n",
      "14123/14123 [==============================] - 2s 120us/step - loss: 0.0030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe1ad7d3da0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_logger = CSVLogger('training2.log')\n",
    "model2.fit(x, y, epochs = 100, batch_size=1024, callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5320358250086118\n"
     ]
    }
   ],
   "source": [
    "cnt1 = 0\n",
    "cnt2 = 0\n",
    "for i in range(x_test.shape[0]):\n",
    "    x = x_test[i].reshape(1, x_test.shape[1])\n",
    "    y = model1.predict(x, batch_size = 128)\n",
    "    y_idx = np.argsort(y[0])\n",
    "    y_idx = y_idx[-10:]\n",
    "    if np.where(y_test[i] == 1) in y_idx:\n",
    "        cnt1 += 1\n",
    "    cnt2 += 1\n",
    "print(cnt1 / cnt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9109288205658184\n"
     ]
    }
   ],
   "source": [
    "cnt1 = 0\n",
    "cnt2 = 0\n",
    "for i in range(x_train.shape[0]):\n",
    "    x = x_train[i].reshape(1, x_train.shape[1])\n",
    "    y = model1.predict(x, batch_size = 128)\n",
    "    y_idx = np.argsort(y[0])\n",
    "    y_idx = y_idx[-10:]\n",
    "    if np.where(y_train[i] == 1) in y_idx:\n",
    "        cnt1 += 1\n",
    "    cnt2 += 1\n",
    "print(cnt1 / cnt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(x_idx):\n",
    "    x = np.zeros((1, ingred.shape[1]))\n",
    "    x[0, x_idx] = 1\n",
    "    y = model1.predict(x, batch_size = 128)\n",
    "    y_idx = np.argsort(y[0])\n",
    "    y_idx = y_idx[-10:]\n",
    "    print(keptcolumns[y_idx + 6])\n",
    "    print(y[0][y_idx])\n",
    "    h_val = np.zeros(10)\n",
    "    for i in range(10):\n",
    "        x_tmp = np.append(x_idx, y_idx[i])\n",
    "        x = np.zeros((1, 308))\n",
    "        x[0, x_tmp] = 1        \n",
    "        y_tmp = model2.predict(x, batch_size = 128)\n",
    "        h_val[i] = y_tmp\n",
    "    y_idx_idx = np.argsort(h_val)\n",
    "    y_idx = y_idx[y_idx_idx]\n",
    "    print(keptcolumns[y_idx + 6])\n",
    "    print(h_val[y_idx_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuna, Asparagus, and New Potato Salad with Chive Vinaigrette and Fried Capers \n",
      "[[  8  46 219 230 289]]\n",
      "[['asparagus' 'capers' 'potato' 'radish' 'tuna']]\n",
      "Suggestions:\n",
      "['mushroom' 'onion' 'olive' 'fennel' 'bean' 'green bean' 'cauliflower'\n",
      " 'chicken' 'egg' 'tuna']\n",
      "[0.01371816 0.01823738 0.02338681 0.02453548 0.0288403  0.03039324\n",
      " 0.0519034  0.74252915 0.9438875  0.9443097 ]\n",
      "['green bean' 'chicken' 'tuna' 'bean' 'onion' 'olive' 'mushroom' 'egg'\n",
      " 'cauliflower' 'fennel']\n",
      "[0.02723945 0.04097425 0.04493065 0.05182261 0.05846273 0.06598619\n",
      " 0.08816563 0.08823858 0.09497377 0.09989666]\n"
     ]
    }
   ],
   "source": [
    "rec_no = 15\n",
    "print(h_val[rec_no][0])\n",
    "idx = np.array(np.where(ingred[rec_no] == 1))\n",
    "print(idx)\n",
    "print(keptcolumns[idx + 6])\n",
    "print('Suggestions:')\n",
    "test_model(np.array([8, 46, 219, 230]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
